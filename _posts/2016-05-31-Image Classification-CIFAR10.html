---
layout: post
title: Image Classification - CIFAR10
description: An essay about image classification, using CIFAR10 dataset dataset to train a spatially-sparse convolutional neural network to do the image classification.
tags: 
    - Image Classification
    - CIFAR10
    - SparseConvNet
    - CUDA
    - Affine Transformation
---

<div><p class="c19 c28"><span class="c0"></span></p><p class="c27 c28 c36 c48"><span class="c0"></span></p></div><p class="c27 c55 title" id="h.294j0hfkierl"><span class="c39">Image Classification </span></p><p class="c19"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;May 31, 2016</span></p><p class="c31 c27"><span>Students: </span><span>Tao Ren @ Queens College</span></p><p class="c31 c27"><span class="c0">Professor: Chao Chen</span></p><p class="c2 c28"><span class="c0"></span></p><h1 class="c47" id="h.mljvl1myqxb3"><span class="c33 c4">Problem</span></h1><p class="c19"><span>Our project is Image Classification and the problem we have for this project is that Machines does not recognize things in the picture. For example, if you give mechine a picture and inside the picture is a dog, how can machines know there is a dog in the picture? &nbsp; </span></p><h1 class="c47" id="h.sspx41ab79z3"><span class="c33 c4">Goal</span></h1><p class="c19"><span>The goal for our project is that Feed 50,000 images to training set and use 10,000 to test. And use three different methods to test the accuracy.</span></p><h1 class="c47 c27" id="h.e7tmd692pxje"><span class="c33 c4">DataSet</span></h1><p class="c2"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The DataSet we use is CIFAR-10. CIFAR-10 is a subset of the 80 million tiny images dataset and consists of 60,000 32 * 32 color images containing one of 10 object classes, with 6000 images per class.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c27 c57"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 472.00px; height: 365.00px;"><img alt="" src="images/image32.png" style="width: 472.00px; height: 365.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span>Figure 1: The catalog of CIFAR-10, images are from </span><span class="c64"><a class="c7" href="https://www.google.com/url?q=http://www.cs.toronto.edu/~kriz/cifar.html&amp;sa=D&amp;ust=1500874760910000&amp;usg=AFQjCNHhOeuk2q39HJ4HYn0ZyP3_lkBQOw">http://www.cs.toronto.edu/~kriz/cifar.html</a></span><span>&nbsp;website</span><span class="c0">.</span></p><p class="c2 c28"><span class="c0"></span></p><hr style="page-break-before:always;display:none;"><h1 class="c40" id="h.f33lucvs9sza"><span class="c33 c4"></span></h1><h1 class="c47" id="h.j3epc0ve3yds"><span class="c4 c33">Fractional Max-Pooling with CNN</span></h1><h2 class="c29" id="h.so4mv8pw130m"><span class="c23 c4">Overview</span></h2><p class="c2"><span class="c0">Convolutional networks almost always incorporate some form of spatial pooling, and very often it is &nbsp; &nbsp;max-pooling with &nbsp;= 2. Max-pooling act on the hidden layers of the network, reducing their size by an integer multiplicative factor . The amazing by-product of discarding 75% of</span></p><p class="c2"><span class="c0">your data is that you build into the network a degree of invariance with respect to translations and elastic distortions. However, if you simply alternate convolutional layers with max-pooling layers, performance is limited due to the rapid reduction in spatial size, and the disjoint nature</span></p><p class="c2"><span class="c0">of the pooling regions. A fractional version of max-pooling where &nbsp;is allowed to take non-integer values. Our version of max-pooling is stochastic as there are lots of different ways of constructing suitable pooling regions. </span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c12" id="h.1xozi13l9qrg"><span>Convolutional </span><span>Neural </span><span class="c23 c4">Networks Architecture</span></h2><p class="c2"><span>Compared to regular Neural Network, </span><span>Convolutional Neural Networks take advantage of the fact that the input consists of images and they constrain the architecture in a more sensible way. In particular, unlike a regular Neural Network, the layers of a ConvNet have neurons arranged in 3 dimensions: width, height, depth. (Note that the word </span><span>depth </span><span class="c0">here refers to the third dimension of an activation volume, not to the depth of a full Neural Network, which can refer to the total number of layers in a network.) The input images in CIFAR-10 are an input volume of activations, and the volume has dimensions 32x32x3 (width, height, depth respectively). As we will soon see, the neurons in a layer will only be connected to a small region of the layer before it, instead of all of the neurons in a fully-connected manner. Moreover, the final output layer would for CIFAR-10 have dimensions 1x1x10, because by the end of the ConvNet architecture we will reduce the full image into a single vector of class scores, arranged along the depth dimension. Here is a visualization:</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 226.67px;"><img alt="" src="images/image25.png" style="width: 624.00px; height: 226.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><h2 class="c12" id="h.r4la02bbbvge"><span class="c23 c4">Layers used to build ConvNets</span></h2><p class="c2"><span>As we described above, a simple ConvNet is a sequence of layers, and every layer of a ConvNet transforms one volume of activations to another through a differentiable function. We use three main types of layers to build ConvNet architectures: </span><span class="c4">Convolutional Layer</span><span>, </span><span class="c4">Pooling Layer</span><span>, and </span><span class="c4">Fully-Connected Layer</span><span class="c0">&nbsp;(exactly as seen in regular Neural Networks). We will stack these layers to form a full ConvNet architecture.</span></p><p class="c50 c27"><span class="c13 c25">Example Architecture: Overview</span><span class="c0 c13">. We will go into more details below, but a simple ConvNet for CIFAR-10 classification could have the architecture [INPUT - CONV - RELU - POOL - FC]. In more detail:</span></p><ul class="c20 lst-kix_6s4sauspxydw-0 start"><li class="c35 c27"><span class="c0 c13">INPUT [32x32x3] will hold the raw pixel values of the image, in this case an image of width 32, height 32, and with three color channels R,G,B.</span></li><li class="c35 c27"><span class="c0 c13">CONV layer will compute the output of neurons that are connected to local regions in the input, each computing a dot product between their weights and a small region they are connected to in the input volume. This may result in volume such as [32x32x12] if we decided to use 12 filters.</span></li><li class="c27 c35"><span class="c13">RELU layer will apply an elementwise activation function, such as the </span><span class="c13 c54">max(0,x)</span><span class="c13">&nbsp;</span><span class="c0 c13">thresholding at zero. This leaves the size of the volume unchanged ([32x32x12]).</span></li><li class="c35 c27"><span class="c0 c13">POOL layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in volume such as [16x16x12].</span></li><li class="c35 c27"><span class="c0 c13">FC (i.e. fully-connected) layer will compute the class scores, resulting in volume of size [1x1x10], where each of the 10 numbers correspond to a class score, such as among the 10 categories of CIFAR-10. As with ordinary Neural Networks and as the name implies, each neuron in this layer will be connected to all the numbers in the previous volume.</span></li></ul><p class="c2"><span class="c0">In this way, ConvNets transform the original image layer by layer from the original pixel values to the final class scores. Note that some layers contain parameters and other don&rsquo;t. In particular, the CONV/FC layers perform transformations that are a function of not only the activations in the input volume, but also of the parameters (the weights and biases of the neurons). On the other hand, the RELU/POOL layers will implement a fixed function. The parameters in the CONV/FC layers will be trained with gradient descent so that the class scores that the ConvNet computes are consistent with the labels in the training set for each image.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 298.67px;"><img alt="" src="images/image37.png" style="width: 624.00px; height: 298.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 262.67px;"><img alt="" src="images/image34.png" style="width: 624.00px; height: 262.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c12" id="h.rkne6163k4oi"><span class="c23 c4">Convolutional Layer</span></h2><p class="c2"><span class="c0">The Conv layer is the core building block of a Convolutional Network that does most of the computational heavy lifting.</span></p><p class="c22"><span class="c4">Overview. </span><span class="c0">The CONV layer&rsquo;s parameters consist of a set of learnable filters. Every filter is small spatially (along width and height), but extends through the full depth of the input volume. For example, a typical filter on a first layer of a ConvNet might have size 5x5x3 (i.e. 5 pixels width and height, and 3 because images have depth 3, the color channels). During the forward pass, we slide (more precisely, convolve) each filter across the width and height of the input volume and compute dot products between the entries of the filter and the input at any position. As we slide the filter over the width and height of the input volume we will produce a 2-dimensional activation map that gives the responses of that filter at every spatial position. Intuitively, the network will learn filters that activate when they see some type of visual feature such as an edge of some orientation or a blotch of some color on the first layer, or eventually entire honeycomb or wheel-like patterns on higher layers of the network. Now, we will have an entire set of filters in each CONV layer (e.g. 12 filters), and each of them will produce a separate 2-dimensional activation map. We will stack these activation maps along the depth dimension and produce the output volume.</span></p><p class="c22"><span class="c4">Local Connectivity.</span><span>&nbsp;When dealing with high-dimensional inputs such as images, as we saw above it is impractical to connect neurons to all neurons in the previous volume. Instead, we will connect each neuron to only a local region of the input volume. The spatial extent of this connectivity is a hyperparameter called the </span><span>receptive field</span><span class="c0">&nbsp;of the neuron (equivalently this is the filter size). The extent of the connectivity along the depth axis is always equal to the depth of the input volume. It is important to emphasize again this asymmetry in how we treat the spatial dimensions (width and height) and the depth dimension: The connections are local in space (along width and height), but always full along the entire depth of the input volume.</span></p><p class="c22"><span class="c4">Spatial arrangement.</span><span class="c0">&nbsp;We have explained the connectivity of each neuron in the Conv Layer to the input volume, but we haven&rsquo;t yet discussed how many neurons there are in the output volume or how they are arranged. Three hyperparameters control the size of the output volume: the depth, stride and zero-padding.</span></p><ol class="c20 lst-kix_6ohqyaha5qaa-0 start" start="1"><li class="c45 c27"><span class="c13">First, the </span><span class="c13 c4">depth</span><span class="c13">&nbsp;of the output volume is a hyperparameter: it corresponds to the number of filters we would like to use, each learning to look for something different in the input. For example, if the first Convolutional Layer takes as input the raw image, then different neurons along the depth dimension may activate in presence of various oriented edged, or blobs of color. We will refer to a set of neurons that are all looking at the same region of the input as a </span><span class="c13 c4">depth column</span><span class="c13">&nbsp;(some people also prefer the term </span><span class="c13 c25">fibre</span><span class="c0 c13">).</span></li><li class="c45 c27"><span class="c13">Second, we must specify the </span><span class="c13 c4">stride</span><span class="c0 c13">&nbsp;with which we slide the filter. When the stride is 1 then we move the filters one pixel at a time. When the stride is 2 (or uncommonly 3 or more, though this is rare in practice) then the filters jump 2 pixels at a time as we slide them around. This will produce smaller output volumes spatially.</span></li><li class="c45 c27"><span class="c13">As we will soon see, sometimes it will be convenient to pad the input volume with zeros around the border. The size of this </span><span class="c13 c4">zero-padding</span><span class="c0 c13">&nbsp;is a hyperparameter. The nice feature of zero padding is that it will allow us to control the spatial size of the output volumes (most commonly as we&rsquo;ll see soon we will use it to exactly preserve the spatial size of the input volume so the input and output width and height are the same).</span></li></ol><p class="c2"><span>We can compute the spatial size of the output volume as a function of the input volume size (</span><span>W</span><span>), the receptive field size of the Conv Layer neurons (</span><span>F</span><span>), the stride with which they are applied (</span><span>S</span><span>S), and the amount of zero padding used (</span><span>P</span><span>) on the border. You can convince yourself that the correct formula for calculating how many neurons &ldquo;fit&rdquo; is given by </span><span>(W&minus;F+2P)/S+1</span><span class="c0">(W&minus;F+2P)/S+1. For example for a 7x7 input and a 3x3 filter with stride 1 and pad 0 we would get a 5x5 output. With stride 2 we would get a 3x3 output.</span></p><p class="c38 c27"><span class="c13 c4">Implementation as Matrix Multiplication</span><span class="c0 c13">. Note that the convolution operation essentially performs dot products between the filters and local regions of the input. A common implementation pattern of the CONV layer is to take advantage of this fact and formulate the forward pass of a convolutional layer as one big matrix multiply as follows:</span></p><ol class="c20 lst-kix_f4vv2bn7s2ea-0 start" start="1"><li class="c45 c27"><span class="c13">The local regions in the input image are stretched out into columns in an operation commonly called </span><span class="c13 c4">im2col</span><span class="c13">. For example, if the input is [227x227x3] and it is to be convolved with 11x11x3 filters at stride 4, then we would take [11x11x3] blocks of pixels in the input and stretch each block into a column vector of size 11*11*3 = 363. Iterating this process in the input at stride of 4 gives (227-11)/4+1 = 55 locations along both width and height, leading to an output matrix </span><span class="c13">X_col</span><span class="c13">&nbsp;of </span><span class="c13">im</span><span class="c13 c25">2col</span><span class="c0 c13">&nbsp;of size [363 x 3025], where every column is a stretched out receptive field and there are 55*55 = 3025 of them in total. Note that since the receptive fields overlap, every number in the input volume may be duplicated in multiple distinct columns.</span></li><li class="c45 c27"><span class="c13">The weights of the CONV layer are similarly stretched out into rows. For example, if there are 96 filters of size [11x11x3] this would give a matrix </span><span class="c13">W_row</span><span class="c0 c13">&nbsp;of size [96 x 363].</span></li><li class="c27 c45"><span class="c13">The result of a convolution is now equivalent to performing one large matrix multiply </span><span class="c13">np.dot(W_row, X_col)</span><span class="c0 c13">, which evaluates the dot product between every filter and every receptive field location. In our example, the output of this operation would be [96 x 3025], giving the output of the dot product of each filter at each location.</span></li><li class="c45 c27"><span class="c0 c13">The result must finally be reshaped back to its proper output dimension [55x55x96].</span></li></ol><p class="c38 c27"><span class="c13">This approach has the downside that it can use a lot of memory, since some values in the input volume are replicated multiple times in </span><span class="c13">X_col</span><span class="c0 c13">. However, the benefit is that there are many very efficient implementations of Matrix Multiplication that we can take advantage of.</span></p><p class="c27 c38"><span class="c13 c4">Backpropagation.</span><span class="c0 c13">&nbsp;The backward pass for a convolution operation (for both the data and the weights) is also a convolution (but with spatially-flipped filters). </span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c29 c43" id="h.q0abj4kpl66o"><span class="c13 c4 c58"></span></h2><h2 class="c12 c43" id="h.z5w1kt4gjmfk"><span class="c23 c4"></span></h2><h2 class="c12" id="h.apckbhcd1myp"><span class="c23 c4">Network-in-Network Layer</span></h2><p class="c2"><span class="c11">An NiN layer is a convolutional layer where the filters have spatial</span><span>&nbsp;</span><span class="c11">size just 1</span><span>&nbsp;x </span><span class="c11">1. They can be thought of as single layer networks that increase the</span><span>&nbsp;</span><span class="c11">learning power of a convolutional layer without changing the spatial structure.</span><span>&nbsp;</span><span class="c11">We placed NiN layers after each max-pooling layer and the final convolutional</span><span>&nbsp;</span><span class="c0">layer.</span></p><h2 class="c12 c43" id="h.yqoq7yizwyrd"><span class="c23 c4"></span></h2><h2 class="c12" id="h.gn7l0ji5vbvt"><span>A</span><span class="c23 c4">ctivation function</span></h2><p class="c27 c50"><span class="c4">Leaky ReLU</span><span>.</span><span>&nbsp;Leaky ReLUs are one attempt to fix the &ldquo;dying ReLU&rdquo; problem. Instead of the function being zero when x &lt; 0, a leaky ReLU will instead have a small negative slope (of 0.33). That is, the function computes </span><span>f(x)=&#x1d7d9;(x&lt;0)(&alpha;x)+&#x1d7d9;(x&gt;=0)(x)</span><span class="c0">&nbsp;where &alpha; is &#8531;.</span></p><p class="c31 c27"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 255.00px; height: 98.00px;"><img alt="" src="images/image12.png" style="width: 255.00px; height: 98.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c31 c27 c28"><span class="c0"></span></p><h2 class="c12" id="h.2jciucltt59n"><span class="c23 c4">Softmax classifier</span></h2><p class="c2"><span>It turns out that the SVM is one of two commonly seen classifiers. The other popular choice is the </span><span>Softmax classifier</span><span>, which has a different loss function. If you&rsquo;ve heard of the binary Logistic Regression classifier before, the Softmax classifier is its generalization to multiple classes. Unlike the SVM which treats the outputs f(x</span><span class="c9">i</span><span>,W) as (uncalibrated and possibly difficult to interpret) scores for each class, the Softmax classifier gives a slightly more intuitive output (normalized class probabilities) and also has a probabilistic interpretation that we will describe shortly. In the Softmax classifier, the function mapping </span><span>f(x</span><span class="c9">i</span><span>;W)=Wx</span><span class="c9">i</span><span>&nbsp;stays unchanged, but we now interpret these scores as the unnormalized log probabilities for each class and replace the </span><span>hinge loss</span><span>&nbsp;with a </span><span>cross-entropy loss</span><span class="c0">&nbsp;that has the form:</span></p><p class="c27 c56"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 470.00px; height: 66.83px;"><img alt="" src="images/image15.png" style="width: 470.00px; height: 66.83px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span>where we are using the notation </span><span>f</span><span>j</span><span>&nbsp;to mean the j-th element of the vector of class scores </span><span>f</span><span>. As before, the full loss for the dataset is the mean of </span><span>L</span><span>i</span><span>&nbsp;over all training examples together with a regularization term </span><span>R(W)</span><span>. The function </span><span>f</span><span>j</span><span>(z)=</span><span>e</span><span class="c21">zj</span><span>/</span><span>&sum;</span><span class="c9">k</span><span>e</span><span class="c21">zk</span><span>&nbsp;is called the </span><span>softmax function</span><span>: It takes a vector of arbitrary real-valued scores (in </span><span>z</span><span class="c0">) and squashes it to a vector of values between zero and one that sum to one. The full cross-entropy loss that involves the softmax function might look scary if you&rsquo;re seeing it for the first time but it is relatively easy to motivate.</span></p><p class="c2"><span class="c4">Information theory view</span><span>. The </span><span>cross-entropy</span><span>&nbsp;between a &ldquo;true&rdquo; distribution p and an estimated distribution </span><span>q</span><span class="c0">q is defined as:</span></p><p class="c2 c18 c36"><span>H(p,q)=&minus;&sum;</span><span class="c9">x</span><span class="c0">p(x)log&#8289;q(x)</span></p><p class="c2"><span>The Softmax classifier is hence minimizing the cross-entropy between the estimated class probabilities ( </span><span>q=e</span><span class="c21">f</span><span class="c21">yi</span><span>/&sum;</span><span class="c9">j</span><span>e</span><span class="c21">f</span><span class="c21">j</span><span>&nbsp;as seen above) and the &ldquo;true&rdquo; distribution, which in this interpretation is the distribution where all probability mass is on the correct class (i.e. </span><span>p=[0,&hellip;1,&hellip;,0]</span><span>&nbsp;contains a single 1 at the </span><span>y</span><span class="c9">i</span><span class="c0">-th position.). </span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 306.67px;"><img alt="" src="images/image30.png" style="width: 624.00px; height: 306.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">We can use the cross-entropy loss to train the convolutional neural network.</span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c12" id="h.ezy30vb9ql5i"><span class="c23 c4">Spatial sparsity for convolutional networks</span></h2><p class="c2"><span class="c0">Imagine putting an all-zero array into the input layer of a CNN. As you evaluate the network in the forward direction, the translational invariance of the input is propagated to each of the hidden layers in turn. We can therefore think of each hidden variable as having a ground state corresponding to receiving no meaningful input; the ground state is generally non-zero because of bias terms. When the input array is sparse, you only have to calculate the values of the hidden variables where they differ from their ground state. Figure S1 shows how the active spatial locations change through the layers.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 161.33px;"><img alt="" src="images/image26.png" style="width: 624.00px; height: 161.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Figure S1: The active spatial locations (black) when a circle with diameter 32 is placed in the center of a 94 &times; 94 input layer and fed forward. Sparsity is most important in the early stages where most of the spatial locations are in their ground state (gray).</span></p><p class="c22"><span class="c0">Essentially, we want to memoize the convolutional and pooling operations. Memoizing can be done using a hash table, but that would be inefficient here as for each operation there is only one input, corresponding to regions in the ground state, that we expect to see repeatedly. </span></p><p class="c2"><span class="c0">Instead, to forward propagate the network we calculate two matrices for each layer of the network:</span></p><ul class="c20 lst-kix_1ywg1ptnt6s3-0 start"><li class="c2 c17"><span class="c0">A feature matrix which is a list of row vectors, one for the ground state, and one for each active spatial location in the layer; the width of the matrix is the number of features per spatial location.</span></li><li class="c2 c17"><span class="c0">A pointer matrix with size equal to the spatial size of the convolutional layer. For each spatial location in the convolutional layer, we store the number of the corresponding row in the feature matrix.</span></li></ul><p class="c22"><span class="c0">This representation is very loosely biologically inspired. The human visual cortex separates into two streams of information: the dorsal (where) and ventral (what) streams. Similar data structures can be used in reverse order for backpropagation.</span></p><p class="c22"><span class="c0">For a regular convolutional network, the convolutional and pooling operations within a layer can be performed in parallel on a GPU (or even spread over multiple GPUs). Exactly the same holds here; there is simply less work to do as we know the inactive output spatial locations are all the same.</span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c29" id="h.1hf6i3ojgfn5"><span class="c23 c4">Dropout</span></h2><p class="c2"><span class="c0">Model combination nearly always improves the performance of machine learning methods. With large neural networks, however, the obvious idea of averaging the outputs of many separately trained nets is prohibitively expensive. Combining several models is most helpful when the individual models are different from each other and in order to make neural net models different, they should either have different architectures or be trained on different data. Training many different architectures is hard because finding optimal hyperparameters for each architecture is a daunting task and training each large network requires a lot of computation. Moreover, large networks normally require large amounts of training data and there may not be enough data available to train different networks on different subsets of the data. Even if one was able to train many different large networks, using them all at test time is infeasible in applications where it is important to respond quickly.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 413.00px; height: 218.00px;"><img alt="" src="images/image11.png" style="width: 413.00px; height: 218.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c0">Figure D1</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c0">Dropout is a technique that addresses both these issues. It prevents overfitting and provides a way of approximately combining exponentially many different neural network architectures efficiently. The term &ldquo;dropout&rdquo; refers to dropping out units (hidden and visible) in a neural network. By dropping a unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections, as shown in Figure D1. The choice of which units to drop is random. In the simplest case, each unit is retained with a fixed probability p independent of other units, where p can be chosen using a validation set or can simply be set at 0.5, which seems to be close to optimal for a wide range of networks and tasks. For the input units, however, the optimal probability of retention is usually closer to 1 than to 0.5.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 468.00px; height: 133.00px;"><img alt="" src="images/image9.png" style="width: 468.00px; height: 133.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span><span class="c0">Figure D2</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span>Applying dropout to a neural network amounts to sampling a &ldquo;thinned&rdquo; network from it. The thinned network consists of all the units that survived dropout (Figure D1.b). A neural net with n units, can be seen as a collection of 2n possible thinned neural networks. These networks all share weights so that the total number of parameters is still O(n</span><span class="c21">2</span><span class="c0">), or less. For each presentation of each training case, a new thinned network is sampled and trained. So training a neural network with dropout can be seen as training a collection of 2n thinned networks with extensive weight sharing, where each thinned network gets trained very rarely, if at all.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span>At test time, it is not feasible to explicitly average the predictions from exponentially many thinned models. However, a very simple approximate averaging method works well in practice. The idea is to use a single neural net at test time without dropout. The weights of this network are scaled-down versions of the trained weights. If a unit is retained with probability p during training, the outgoing weights of that unit are multiplied by p at test time as shown in Figure D2. This ensures that for any hidden unit the expected output (under the distribution used to drop units at training time) is the same as the actual output at test time. By doing this scaling, 2</span><span class="c21">n</span><span class="c0">&nbsp;networks with shared weights can be combined into a single neural network to be used at test time. We found that training a network with dropout and using this approximate averaging method at test time leads to significantly lower generalization error on a wide variety of classification problems compared to training with other regularization methods.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span>Consider a neural network with L hidden layers. Let </span><span class="c25">l</span><img src="images/image1.png"><span>{1,...,L} index the hidden layers of the network. Let z</span><span class="c21">(l)</span><span>&nbsp;denote the vector of inputs into layer </span><span class="c25">l</span><span>, y</span><span class="c21">(l)</span><span>&nbsp;denote the vector of outputs from layer </span><span class="c25">l</span><span>&nbsp;(y</span><span class="c21">(0)</span><span>&nbsp;= x is the input). W</span><span class="c21">(l)</span><span>&nbsp;and b</span><span class="c21">(l)</span><span>&nbsp;are the weights and biases at layer </span><span class="c25">l</span><span>. The feed-forward operation of a standard neural network can be described as (for </span><span class="c25">l</span><img src="images/image1.png"><span>{1,...,L} and any hidden unit </span><span class="c25">i</span><span class="c0">)</span></p><p class="c2 c53"><span>z</span><span class="c9">i</span><span class="c21">(l+1) </span><span>&nbsp;= w</span><span class="c9">i</span><span class="c21">(l+1)</span><span>&nbsp;y</span><span class="c21">l</span><span>&nbsp;+ b</span><span class="c9">i</span><span class="c21">(l+1)</span><span class="c0">&nbsp;,</span></p><p class="c2 c53"><span>y</span><span class="c9">i</span><span class="c21">(l+1) </span><span>&nbsp;= f(z</span><span class="c9">i</span><span class="c21">(l+1)</span><span class="c0">&nbsp;) ,</span></p><p class="c2"><span>where f is the activation function, here is Leaky ReLU: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 141.78px; height: 54.47px;"><img alt="" src="images/image12.png" style="width: 141.78px; height: 54.47px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">With dropout, the feed-forward operation becomes</span></p><p class="c2 c46 c36"><span>r</span><span class="c9">j</span><span class="c21">(l) </span><span class="c0">&nbsp; &nbsp; &nbsp;~ Bernoulli(p),</span></p><p class="c2 c46 c36"><img src="images/image2.png"><span class="c21">(l) </span><span>&nbsp; &nbsp;= r</span><span class="c21">(l)</span><span>&nbsp;* y</span><span class="c21">(l)</span><span class="c0">,</span></p><p class="c2 c53"><span>z</span><span class="c9">i</span><span class="c21">(l+1) </span><span>&nbsp;= w</span><span class="c9">i</span><span class="c21">(l+1)</span><img src="images/image2.png"><span class="c21">(l)</span><span>&nbsp;+ b</span><span class="c9">i</span><span class="c21">(l+1)</span><span class="c0">&nbsp;,</span></p><p class="c2 c36 c46"><span>y</span><span class="c9">i</span><span class="c21">(l+1) </span><span>&nbsp;= f(z</span><span class="c9">i</span><span class="c21">(l+1)</span><span class="c0">&nbsp;) ,</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span>Here * denotes an element-wise product. For any layer </span><span class="c25">l</span><span>, r</span><span class="c21">(l)</span><span>&nbsp;is a vector of independent Bernoulli random variables each of which has probability p of being 1. This vector is sampled and multiplied element-wise with the outputs of that layer, y</span><span class="c21">(l)</span><span>, to create the thinned outputs </span><img src="images/image2.png"><span class="c21">(l)</span><span>. The thinned outputs are then used as input to the next layer. This process is applied at each layer. This amounts to sampling a sub-network from a larger network. For learning, the derivatives of the loss function are backpropagated through the sub-network. At test time, the weights are scaled as W</span><span class="c9">test</span><span class="c21">(l)</span><span>= pW</span><span class="c21">(l)</span><span class="c0">. The resulting neural network is used without dropout.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 329.33px;"><img alt="" src="images/image22.png" style="width: 624.00px; height: 329.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c12" id="h.jd3ivq4n7mj2"><span class="c23 c4">Fractional max-pooling (FMP)</span></h2><p class="c2"><span class="c11">The idea of FMP is to reduce the spatial size</span><span>&nbsp;</span><span class="c11">of the image by a factor of &nbsp; with 1 &lt; &alpha; &nbsp;&lt; 2 . Like stochastic pooling, FMP</span><span>&nbsp;</span><span class="c11">introduces a degree of randomness to the pooling process. However, unlike</span><span>&nbsp;</span><span class="c11">stochastic-pooling, the randomness is related to the choice of pooling regions,</span><span>&nbsp;</span><span class="c11">not the way pooling is performed inside each of the pooling regions.</span><span>&nbsp;</span><span class="c11">Briefly,</span><span>&nbsp;</span><span class="c0">there are three choices that affect the way FMP is implemented:</span></p><ul class="c20 lst-kix_howgz96qwmhr-0 start"><li class="c2 c17"><span class="c11">The pooling fraction which determines the ratio between the spatial</span><span>&nbsp;</span><span class="c11">sizes of the input and the output of the pooling layer. Regular 2 x 2</span><span>&nbsp;</span><span class="c11">&nbsp;max-pooling corresponds to the special</span><span>&nbsp;</span><span class="c11">case </span><span>&alpha;</span><span class="c0">&nbsp;= 2 .</span></li><li class="c2 c17"><span class="c11">The pooling regions can either be chosen in a random or a pseudorandom</span><span>&nbsp;</span><span class="c11">fashion. There seems to be a trade off between the use of randomness in</span><span>&nbsp;</span><span class="c11">FMP and the use of dropout and/or training data augmentation. Random-FMP seems to work better on its own; however, when combined with &lsquo;too</span><span>&nbsp;</span><span class="c11">much&rsquo; dropout or training data augmentation,</span><span>&nbsp;</span><span class="c0">underfitting can occur.</span></li><li class="c2 c17"><span class="c11">The pooling regions can be either disjoint or overlapping. Disjoint regions</span><span>&nbsp;</span><span class="c0">are easier to picture, but we find that overlapping regions work better.</span></li></ul><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c11">Each convolutional filter of a CNN produces a matrix of hidden variables. The</span><span>&nbsp;</span><span class="c11">size of this matrix is often reduced using some form of pooling. Max-pooling is a procedure that takes an N</span><span class="c11 c9">in</span><span class="c11">&nbsp;&times; N</span><span class="c11 c9">in</span><span class="c11">&nbsp;input matrix and returns a smaller output</span><span>&nbsp;</span><span class="c11">matrix, say N</span><span class="c11 c9">out</span><span class="c11">&nbsp;&times; N</span><span class="c11 c9">out</span><span class="c11">. This is achieved by dividing the N</span><span class="c11 c9">in</span><span class="c11">&nbsp;&times; N</span><span class="c11 c9">in</span><span class="c11">&nbsp;square into</span><span>&nbsp;</span><span class="c11">N</span><span class="c11 c9">out</span><span class="c21">2</span><span class="c11">&nbsp;pooling regions (P</span><span class="c11 c9">i,j</span><span class="c0">&nbsp;):</span></p><p class="c2 c36"><span class="c11">P</span><span class="c11 c9">i,j</span><span class="c11">&nbsp;&sub; {1, 2, . . . , N</span><span class="c11 c9">in</span><span class="c11">}</span><span class="c11 c21">2</span><span>&nbsp;for each (i, j) &isin; {1, . . . , N</span><span class="c9">out</span><span>}</span><span class="c11 c21 c65">2</span></p><p class="c2"><span class="c0">and then setting</span></p><p class="c2 c18 c36"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 209.50px; height: 31.15px;"><img alt="" src="images/image36.png" style="width: 209.50px; height: 31.15px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span>I</span><span class="c11">f we take N</span><span class="c11 c9">in</span><span class="c11">/N</span><span class="c11 c9">out</span><span class="c11">&nbsp;&asymp;</span><img src="images/image3.png"><span>&nbsp;</span><span class="c11">then the rate of decay of the spatial size of interesting features is n times slower.</span><span>&nbsp;</span><span class="c11">For clarity we will now focus on the case N</span><span class="c11 c9">in</span><span class="c11">/N</span><span class="c11 c9">out</span><span class="c11">&nbsp;&isin; (1, 2) as we are primarily</span><span>&nbsp;</span><span class="c11">interested in accuracy; if speed is an overbearing concern then FMP could be</span><span>&nbsp;</span><span class="c11">applied with N</span><span class="c11 c9">in</span><span class="c11">/N</span><span class="c11 c9">out</span><span class="c0">&nbsp;&isin; (2, 3).</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c11">Given a particular pair of values (N</span><span class="c11 c9">in</span><span class="c11">, N</span><span class="c11 c9">out</span><span class="c11">) we need a way to choose pooling</span><span>&nbsp;</span><span class="c11">regions (P</span><span class="c11 c9">i,j</span><span class="c11">&nbsp;). We will consider two type of arrangements, overlapping squares</span><span>&nbsp;</span><span class="c11">and disjoint collections of</span><span>&nbsp;</span><span class="c11">rectangles. In Figure F1 we show a number of different</span><span>&nbsp;</span><span class="c11">ways of dividing up a 36 &times; 36 square grid into disjoint rectangles. Pictures</span><span>&nbsp;</span><span class="c11">two, three and six in Figure F1 can also be used to define an arrangement of</span><span>&nbsp;</span><span class="c11">overlapping 2 &times; 2 squares: take the top left hand corner of each rectangle in the</span><span>&nbsp;</span><span class="c0">picture to be the top left hand corner of one of the squares.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 109.33px;"><img alt="" src="images/image17.png" style="width: 624.00px; height: 109.33px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span>Figure F1</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c11">To give a formal description of how to generate pooling regions, let (a</span><span class="c11 c9">i</span><span class="c11">)</span><span class="c11 c9">i=0</span><span class="c11 c21">Nout</span><span>&nbsp;</span><span class="c11">and (b</span><span class="c11 c9">i</span><span class="c11">)</span><span class="c11 c9">i=0</span><span class="c11 c21">Nout</span><span class="c11">&nbsp;be two increasing sequence of integers starting at 1, ending with</span><span>&nbsp;</span><span class="c11">N</span><span class="c11 c9">in</span><span class="c11">, and with increments all equal to one or two (i.e. a</span><span class="c11 c9">i+1</span><span class="c11">&nbsp;&minus; a</span><span class="c11 c9">i</span><span class="c11">&nbsp;&isin; {1, 2}). The</span><span>&nbsp;</span><span class="c0">regions can then be defined by either</span></p><p class="c2 c36"><span>P = [a</span><span class="c9">i&minus;1</span><span>, a</span><span class="c9">i</span><span>&nbsp;&minus; 1] &times; [b</span><span class="c9">j&minus;1</span><span>, b</span><span class="c9">j</span><span>&nbsp;&minus; 1] or P</span><span class="c9">i,j</span><span>&nbsp;= [a</span><span class="c9">i&minus;1</span><span>, a</span><span class="c9">i</span><span>] &times; [b</span><span class="c9">j&minus;1</span><span>, b</span><span class="c9">j</span><span class="c0">].</span></p><p class="c2"><span>We call the two cases </span><span class="c4">disjoint</span><span>&nbsp;and </span><span class="c4">overlapping</span><span class="c0">, respectively. We have tried two different approaches for generating the integer sequence: using random sequences of numbers and also using pseudorandom sequences.</span></p><p class="c2"><span>We will say that the sequences are </span><span class="c4">random</span><span>&nbsp;if the increments are obtained by taking a random permutation of an appropriate number of ones and twos. We will say that the sequences are </span><span class="c4">pseudorandom</span><span class="c0">&nbsp;if they take the form</span></p><p class="c2 c36"><span>a</span><span class="c9">i</span><span class="c0">&nbsp;= ceiling(&alpha;(i + u)), &alpha; &isin; (1, 2), with some u &isin; (0, 1).</span></p><p class="c2"><span>Below are some patterns of increments corresponding to the case N</span><span class="c9">in</span><span>&nbsp;= 25, N</span><span class="c9">out</span><span class="c0">&nbsp;= 18. The increments on the left were generated &lsquo;randomly&rsquo;, and the increments on the right come from pseudorandom sequences:</span></p><p class="c2 c18 c36"><span class="c0">211112112211112122&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;112112121121211212</span></p><p class="c2 c18 c36"><span class="c0">111222121121112121&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;212112121121121211</span></p><p class="c2 c18 c36"><span class="c0">121122112111211212&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;211211212112121121</span></p><p class="c2"><span class="c0">Although both types of sequences are irregular, the pseudorandom sequences generate much more stable pooling regions than the random ones. To show the effect of randomizing the pooling regions, see Figure F2. We have taken a picture, and we have iteratively used disjoint random pooling regions to reduce the size of the image (taking averages in each pooling region). The result is that the scaled down images show elastic distortion. In contrast, if we use pseudorandom pooling regions, the resulting image is simply a faithfully scaled down version of the original.</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 278.67px;"><img alt="" src="images/image14.png" style="width: 624.00px; height: 278.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span>Figure F2: Top left, &lsquo;Kodak True Color&rsquo; parrots at a resolution of 384 &times; 256. The other five images are one-eighth of the resolution as a result of 6 layers of average pooling using disjoint random FMP</span><img src="images/image4.png"><span class="c0">-pooling regions.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c29" id="h.c8zb8ynsz4pf"><span class="c23 c4">RNG</span></h2><p class="c2"><span class="c0">Random number generator, which is used in this project for dropout and fmp, has some functions:</span></p><ul class="c20 lst-kix_kye0idc3z8ra-0 start"><li class="c2 c17"><span>u</span><span>niform(a, b): Generates</span><span>&nbsp;uniformly distributed integer random number from [a,b)</span></li><li class="c2 c17"><span>n</span><span>ormal: </span><span>Genera</span><span>tes</span><span>&nbsp;random numbers according to the Normal (or Gaussian) random number distribution:</span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 155.31px; height: 35.50px;"><img alt="" src="images/image16.png" style="width: 155.31px; height: 35.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c2 c17"><span>b</span><span>ernoulli: </span><span>Produces random boolean values, according to the discrete probability function: </span><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 130.38px; height: 33.50px;"><img alt="" src="images/image35.png" style="width: 130.38px; height: 33.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></li><li class="c2 c17"><span>NchooseM: Generates</span><span>&nbsp;the </span><span>n choose m</span><span>&nbsp;row randomization matrix/vector. If we want to do dropout, e.g. N input features needs to drop to M output features, NchooseM can generate M random unique index, which we can keep that related M features, and the remain features are dropped.</span></li><li class="c2 c17"><span>p</span><span class="c0">ermutation: Generates a shuffled number sequence: {0,1,...,n-1}. If we want to generate a random pooling regions, we can create an integer array filled with appropriate number of ones and twos, using permutation to generate a shuffled index sequence, accordingly, a shuffled ones and twos. </span></li></ul><p class="c19 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c29" id="h.56zxphngunmm"><span class="c23 c4">Model</span></h2><p class="c2"><span class="c0">Using a random overlapping pooling FMP network, there is a dropout layer between every C2 and FMP layer.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c0">C2: filterSize = 2</span></p><p class="c2"><span class="c0">&nbsp; std::cout &lt;&lt; &quot;Convolution &quot;</span></p><p class="c2"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;&lt; filterSize &lt;&lt;&quot;^&quot; &lt;&lt;dimension&lt;&lt; &quot;x&quot;&lt;&lt; nFeaturesIn</span></p><p class="c2"><span class="c0">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &lt;&lt; &quot;-&gt;&quot; &lt;&lt; nFeaturesOut;</span></p><p class="c2"><span class="c0">F=2, S=1 W1=94, D1=3, P=0</span></p><p class="c2"><span class="c0">W2 = 93, D2=12==&gt;32</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c0">ROFMPSparseConvNet::ROFMPSparseConvNet</span></p><p class="c2 c18"><span class="c0">addLeNetLayerROFMP() (SparseConvNetCUDA.cu)</span></p><p class="c2 c18 c36"><span class="c0">&rarr; addConvolutionalLayer()</span></p><p class="c2 c36 c63"><span class="c0">push( ConvolutionalLayer )</span></p><p class="c2 c18 c36"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&rarr; addLearntLayer()</span></p><p class="c2 c18 c36"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>p</span><span class="c0">ush( NetworkInNetworkLayer )</span></p><p class="c2 c18 c36"><span class="c0">&rarr;push( RandomOverlappingFractionalMaxPoolingLayer )</span></p><p class="c2 c18"><span class="c0">addLeNetLayerMP()</span></p><p class="c2 c18 c36"><span class="c0">&rarr; addConvolutionalLayer()</span></p><p class="c2 c18"><span class="c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&rarr; push( MaxPoolingLayer )</span></p><p class="c2 c18"><span class="c0">addLeNetLayerMP()</span></p><p class="c2 c18"><span class="c0">addSoftmaxLayer()</span></p><p class="c2 c18 c36"><span class="c0">&rarr; addLearntLayer()</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 534.00px; height: 64.00px;"><img alt="" src="images/image40.png" style="width: 534.00px; height: 64.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Dimension: 2</span></p><p class="c2"><span>l</span><span class="c0">: 12 (i = 0; i &lt; l; i+)</span></p><p class="c2"><span>k</span><span class="c0">: 32</span></p><p class="c2"><span>fmpShrik: </span><img src="images/image5.png"></p><p class="c2"><span class="c0">ActivationFunction: VLEAKRELU</span></p><p class="c2"><span class="c0">Input Features: 3</span></p><p class="c2"><span class="c0">Input Class: 10</span></p><p class="c2"><span class="c0">dropout - p: 0.1</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 565.00px; height: 189.00px;"><img alt="" src="images/image39.png" style="width: 565.00px; height: 189.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">ConvolutionalLayer:</span></p><p class="c2"><span class="c0">Features: k * (i + 1)</span></p><p class="c2"><span class="c0">filterSize: 2</span></p><p class="c2"><span class="c0">filterStride: 1</span></p><p class="c2"><span class="c0">poolSize: 2</span></p><p class="c2"><span>fmpShrink: </span><img src="images/image5.png"></p><p class="c2"><span>d</span><span class="c0">ropout: p * i / (l + 1)</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 579.00px; height: 198.00px;"><img alt="" src="images/image33.png" style="width: 579.00px; height: 198.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 587.00px; height: 368.00px;"><img alt="" src="images/image23.png" style="width: 587.00px; height: 368.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">LearntLayer:</span></p><p class="c2"><span class="c0">Features, activationFn, dropout, (filterSize/filterStride/poolingToFollow)^2</span></p><p class="c2"><span class="c0">poolingToFollow==fmpShrink</span></p><p class="c2"><span class="c0">NetworkInNetworkLayer</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 316.00px;"><img alt="" src="images/image13.png" style="width: 600.00px; height: 316.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">ROFMP:</span></p><p class="c2"><span>p</span><span class="c0">oolsize, fmpShrink, dimension</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 393.00px; height: 35.00px;"><img alt="" src="images/image27.png" style="width: 393.00px; height: 35.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Layer sizes of the network:</span></p><p class="c2"><span class="c0">[output]-1-(C1)-1-(C2)-2-(ROFMP)-3-(C2)-4-(ROFMP)-5-(C2)-6-(ROFMP)-8-(C2)-9-(ROFMP)-11-(C2)-12-(ROFMP)-15-(C2)-16-(ROFMP)-20-(C2)-21-(ROFMP)-26-(C2)-27-(ROFMP)-34-(C2)-35-(ROFMP)-44-(C2)-45-(ROFMP)-57-(C2)-58-(ROFMP)-73-(C2)-74-(ROFMP)-93-(C2)-94-[Input]</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c0">Using 50,000 pictures as training set, other remaining 10,000 pictures as test set.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c4 c37">CNN Model to be trained:</span></p><p class="c2"><span>(32nC2 - ROFMP</span><img src="images/image5.png"><span>)</span><span class="c9">12</span><span class="c0">&nbsp;- C2 -C1 - output.</span></p><p class="c31 c27"><span>ROFMP: Pseudorandom Overlapping Fractional Maxing-out Pooling</span></p><a id="t.ea8f74b2693205d3e2399ea5484ba8a10d001b2c"></a><a id="t.0"></a><table class="c52"><tbody><tr class="c60"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">Layer ID</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">Type</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">Spatial Size</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">Depth</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">Filter Spatial Size</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">Filter</span></p><p class="c6"><span class="c0">Activation Function</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">dropout</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><span class="c0">fmpShrik</span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">Input</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">32x32</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">3</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">Affine Transform</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">0</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">94x94</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">12</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">1</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">93x93</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">32</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">2</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">93x93</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">32</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">3</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">74x74</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">128</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">4</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">73x73</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">64</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">5</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">73x73</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">64</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">6</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">58x58</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">256</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">7</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">57x57</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">96</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">8</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">57x57</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">96</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">9</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">45x45</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">384</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">10</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">44x44</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">128</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">11</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">44x44</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">128</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">12</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">35x35</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">512</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">13</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">35x35</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">160</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">14</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">34x34</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">160</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">15</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">27x27</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">640</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">16</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">26x26</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">192</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">17</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">26x26</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">192</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">18</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">21x21</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">768</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">19</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">20x20</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">224</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">20</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">20x20</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">224</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">21</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">16x16</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">896</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">22</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">15x15</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">256</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">23</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">15x15</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">256</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">24</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">12x12</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">1024</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">25</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">11x11</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">288</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.111076</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">26</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">11x11</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">288</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">27</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">9x9</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">1152</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">28</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">8x8</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">320</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0999687</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">29</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">8x8</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">320</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">30</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">6x6</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">1280</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">31</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">5x5</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">352</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0908806</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">32</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">5x5</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">352</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">33</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">4x4</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">1408</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">34</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">3x3</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">384</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0833073</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3 c27"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">35</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">ROFMP</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">3x3</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">384</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c2"><img src="images/image5.png"></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">36</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">C2</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">1536</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">2x2</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">37</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">416</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.076899</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">38</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">NiN</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">448</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">LeakyReLU</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c6"><span class="c0">0.0714062</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c6"><span class="c0">39</span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">FC</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c6"><span class="c0">1x1</span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c6"><span class="c0">10</span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c6"><span class="c0">Softmax</span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td></tr><tr class="c1"><td class="c5" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c14" colspan="1" rowspan="1"><p class="c6"><span class="c0">Output</span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c26" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c24" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c10" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c16" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td><td class="c15" colspan="1" rowspan="1"><p class="c3"><span class="c0"></span></p></td></tr></tbody></table><p class="c2 c28"><span class="c0"></span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c29" id="h.3bhji4xb5m1g"><span class="c4 c23">Extra Dataset into Spatially Sparse Dataset</span></h2><p class="c2"><span class="c0">The SparseConvNet project that we are using read dataset directly from bin format into Spatially Sparse Dataset which combine 3 separated channel data into one pixel.</span></p><p class="c2"><span>According to &nbsp;the CNN Model: (32nC2 - ROFMP</span><img src="images/image5.png"><span>)</span><span class="c9">12</span><span class="c0">&nbsp;- C2 -C1 - output, we can calculate that the training input data&rsquo;s spatial size should be 94x94. The actual input picture&rsquo;s size is 32x32, which will place at the center of a 94x94 sparse grid after the augmentation(see below).</span></p><p class="c2"><span class="c0">&nbsp;</span></p><p class="c2 c28"><span class="c0"></span></p><h2 class="c12" id="h.jpnt0km8r9zx"><span>Training Data Augmentation</span></h2><p class="c2"><span>We extended the training set using affine transformations: a randomized mix of </span><span>scaling</span><span class="c0">, reflections, shearing, rotations, and translation operations. We also added random shifts to the pictures in RGB colorspace.</span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span>W</span><span class="c11">-s</span><span>cale</span><span class="c0">: 0.8~1.2;</span></p><p class="c2"><span>H</span><span>-scale: 0.8~1.2;</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 140.50px; height: 192.26px;"><img alt="" src="images/image31.png" style="width: 140.50px; height: 192.26px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span class="c0">Horizontal flip: 50%;</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 136.66px; height: 172.19px;"><img alt="" src="images/image28.png" style="width: 136.66px; height: 172.19px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span>X-shear: 33% (</span><img src="images/image6.png"><span class="c0">: -0.2~0.2)</span></p><p class="c2"><span>Y-Shear: 33% (</span><img src="images/image7.png"><span class="c0">: -0.2~0.2)</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 280.50px; height: 195.52px;"><img alt="" src="images/image10.png" style="width: 280.50px; height: 195.52px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2"><span>Rotation: 33% (</span><img src="images/image8.png"><span class="c0">: -0.2~0.2)</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 150.28px; height: 186.50px;"><img alt="" src="images/image20.png" style="width: 150.28px; height: 186.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c0">X-translate (offset): -16 ~ 16 pixels</span></p><p class="c2"><span class="c0">Y-translate (offset): -16 ~ 16 pixels</span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 121.10px; height: 164.50px;"><img alt="" src="images/image38.png" style="width: 121.10px; height: 164.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c2 c28"><span class="c0"></span></p><p class="c2"><span class="c0">Color Distortion:</span></p><p class="c31 c27"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 315.50px; height: 152.23px;"><img alt="" src="images/image21.png" style="width: 315.50px; height: 152.23px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c31 c27 c28"><span class="c0"></span></p><p class="c2"><span class="c23 c4">Model averaging</span></p><p class="c22"><span class="c0">Each time we apply an FMP network, either for training or testing purposes, we use different random or pseudorandom sequences to generate the pooling regions. An FMP network can therefore be thought of as an ensemble of similar networks, with each different pooling-region configuration defining a different member of the ensemble. This is similar to dropout; the different values the dropout mask can take define an ensemble of related networks. As with dropout, model averaging for FMP networks can help improve performance. If you classify the same test image a number of times, you may get a number of different predictions. Using majority voting after classifying each test image a number of times can substantially improve accuracy; see below.</span></p><p class="c22"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 371.00px;"><img alt="" src="images/image19.png" style="width: 600.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><h2 class="c29" id="h.14xe9gdj27ub"><span class="c23 c4">Implementation</span></h2><p class="c22"><span>We are using an open source project in: </span><span><a class="c7" href="https://www.google.com/url?q=https://github.com/btgraham/SparseConvNet&amp;sa=D&amp;ust=1500874761081000&amp;usg=AFQjCNFC6fuZITa04Qj3l-TkWNojNDhZ0g">https://github.com/btgraham/SparseConvNet</a></span></p><p class="c22"><span class="c0">We are using a Mac Pro to run the program, with configuration:</span></p><ul class="c20 lst-kix_w79s8etgss24-0 start"><li class="c6 c34 c27"><span class="c0">Mac OS 10.11</span></li><li class="c6 c34 c27"><span class="c0">Intel Core i7 2.30GHz CPU</span></li><li class="c6 c34 c27"><span class="c0">16 GB 1600 MHz DDR3 RAM</span></li><li class="c6 c27 c34"><span class="c0">500GB SSD</span></li><li class="c6 c34 c27"><span class="c0">NVIDIA GeForce GT 750M 2048 MB</span></li></ul><p class="c3 c27"><span class="c0"></span></p><p class="c22"><span class="c0">Because it&rsquo;s a c++ project, need to build using cuda in Ubuntu, we have to change the code a little bit to let the compiler(nvcc) work. Besides, the network training needs around 1.5G memory space, while the GPU just has 750MB free space, we have to change the memory allocation from GPU to main memory, causing the performance drops to 500 seconds per epoch.</span></p><p class="c22"><span>It takes </span><span class="c51">213382 seconds for training 410 epochs to the network, which is almost 60 hours.</span></p><p class="c31 c27 c28"><span class="c0"></span></p><h2 class="c29" id="h.p89dicp9aywh"><span class="c23 c4">Result</span></h2><p class="c22"><span class="c0">The original project achieves 96.53% accuracy, and the project we use achieves 94.8% accuracy after 410 epochs training, the test error of the network is around 5.2%. The network&rsquo;s training mistake drop suddenly from 5.4% to 2.99% after 400 epochs, seems it has over-fitted and we stop the training.</span></p><p class="c27 c31"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 307.13px; height: 240.50px;"><img alt="" src="images/image24.png" style="width: 307.13px; height: 240.50px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title=""></span></p><p class="c31 c27"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 600.00px; height: 371.00px;"><img alt="" src="images/image29.png" style="width: 600.00px; height: 371.00px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c2 c28"><span class="c42"></span></p><p class="c2"><span style="overflow: hidden; display: inline-block; margin: 0.00px 0.00px; border: 0.00px solid #000000; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px); width: 624.00px; height: 350.67px;"><img alt="" src="images/image18.png" style="width: 624.00px; height: 350.67px; margin-left: 0.00px; margin-top: 0.00px; transform: rotate(0.00rad) translateZ(0px); -webkit-transform: rotate(0.00rad) translateZ(0px);" title="Chart"></span></p><p class="c2 c28"><span class="c0"></span></p><h1 class="c47" id="h.1x96snnvh2fe"><span class="c33 c4">Conclusion</span></h1><p class="c2 c36"><span class="c0">We use three different methods to test the accuracy. The first method is Convolutional Neural Networks By Caffe, it is comprised of many convolutional layers. The Accuracy of this method is 78%. Although it is not very high accuracy, the executed time is impressive. The second method is Histogram of Oriented Gradients and linear support vector Machine. HOG features can be described as taking a nonlinear function of the edge orientations in an image and pooling them into small spatial regions to remove sensitivity to exact localisation of the edges. This type of representation has proven particularly successful at being tolerant to non-rigid changes in object geometry whilst maintaining high selectivity.The last method is Fractional max-Polling with CNN, it trained convolutional networks with fractional max-pooling on a number of popular datasets. Although it has high accuracy, the execution time is extremely slow.</span></p><h1 class="c40" id="h.257n8t4hbcc0"><span class="c33 c4"></span></h1><h1 class="c47" id="h.egh6z0uolj34"><span class="c33 c4">Reference</span></h1><ul class="c20 lst-kix_4om7w6c2iqb7-0 start"><li class="c17 c61"><span>CIFAR-10, </span><span class="c41"><a class="c7" href="https://www.google.com/url?q=https://www.kaggle.com/c/cifar-10&amp;sa=D&amp;ust=1500874761085000&amp;usg=AFQjCNFvWErFL7rxh6ksXsaGLKRQnKpmLg">https://www.kaggle.com/c/cifar-10</a></span><span class="c59">&nbsp;</span></li><li class="c2 c17"><span class="c44 c13">CNN with fractional max-pooling: </span><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=http://arxiv.org/pdf/1412.6071v4.pdf&amp;sa=D&amp;ust=1500874761085000&amp;usg=AFQjCNEHuC3RUaFfC0s8Jtli20gCUnBU1g">http://arxiv.org/pdf/1412.6071v4.pdf</a></span></li><li class="c2 c17"><span class="c44 c13">CNN: </span><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=http://cs231n.github.io/convolutional-networks/&amp;sa=D&amp;ust=1500874761086000&amp;usg=AFQjCNG0ttoKjNAba7Q3f0okd2rAfPfaig">http://cs231n.github.io/convolutional-networks/</a></span></li><li class="c2 c17"><span class="c32 c13">Spatially-sparse convolutional neural networks: </span></li></ul><p class="c2 c18 c36"><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=http://arxiv.org/pdf/1409.6070v1.pdf&amp;sa=D&amp;ust=1500874761087000&amp;usg=AFQjCNGO7bUwiPIznSULTIfMVjfOVpbFXg">http://arxiv.org/pdf/1409.6070v1.pdf</a></span><span class="c32 c13">; </span></p><p class="c2 c18 c36"><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=https://github.com/btgraham/SparseConvNet&amp;sa=D&amp;ust=1500874761087000&amp;usg=AFQjCNE7-CgQOKxwDu-QvZbUZySNIXpgeA">https://github.com/btgraham/SparseConvNet</a></span><span class="c32 c13">; </span></p><p class="c2 c18 c36"><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=https://github.com/btgraham/SparseConvNet/wiki/Installation&amp;sa=D&amp;ust=1500874761088000&amp;usg=AFQjCNH1-CilgMuCb4CrkX8T5AvPvVWQ7Q">https://github.com/btgraham/SparseConvNet/wiki/Installation</a></span></p><ul class="c20 lst-kix_4om7w6c2iqb7-0"><li class="c2 c17"><span class="c44 c13">Dropout: </span><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf&amp;sa=D&amp;ust=1500874761088000&amp;usg=AFQjCNF400XvpKvyk6ldJM18_cVKZOS24A">http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf</a></span></li><li class="c2 c17"><span class="c13 c44">CUDA: </span><span class="c44 c13"><a class="c7" href="https://www.google.com/url?q=https://github.com/BVLC/caffe/wiki/Ubuntu-14.04-VirtualBox-VM&amp;sa=D&amp;ust=1500874761089000&amp;usg=AFQjCNE3YEfjzQOmvVOPytq38qsof5149A">https://github.com/BVLC/caffe/wiki/Ubuntu-14.04-VirtualBox-VM</a></span></li><li class="c2 c17"><span class="c44 c13 c62">Neural </span><span class="c44 c13">Network: </span><span class="c41 c13"><a class="c7" href="https://www.google.com/url?q=http://cs231n.github.io/neural-networks-1/&amp;sa=D&amp;ust=1500874761089000&amp;usg=AFQjCNFSwJFsLMfvjME7SDn9rX4PIC49wQ">http://cs231n.github.io/neural-networks-1/</a></span></li><li class="c2 c17"><span class="c44 c13">Affine Transformation: https://en.wikipedia.org/wiki/Transformation_matrix</span></li></ul><p class="c2 c28"><span class="c30"></span></p><p class="c19 c28"><span class="c0"></span></p>